{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e35794",
   "metadata": {},
   "source": [
    "# INSTALLING IMPORTANT TOOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bitsandbytes\n",
    "!pip install accelerate\n",
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fac87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "from transformers import WhisperForConditionalGeneration, WhisperTokenizer, WhisperProcessor\n",
    "from peft import BitsAndBytesConfig, prepare_model_for_kbit_training, LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7550d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWhisperModel(WhisperForConditionalGeneration):\n",
    "    def __init__(self, model_name) :\n",
    "        super().__init__(model_name)\n",
    "        \n",
    "    def forward(self, input_ids=None,\n",
    "                    input_features=None,\n",
    "                    inputs_embeds = None,\n",
    "                    attention_mask=None,\n",
    "                    decoder_input_ids=None,\n",
    "                    decoder_attention_mask=None,\n",
    "                    labels=None,\n",
    "                    decoder_inputs_embeds = None,\n",
    "                    output_attentions=None,\n",
    "                    output_hidden_states=None,\n",
    "                    return_dict=None,\n",
    "                    output_attention= None,\n",
    "                    task_type =None):\n",
    "        \n",
    "        inputs = {\"input_features\": input_ids, 'decoder_input_ids' : decoder_input_ids, 'attention_mask' : attention_mask, 'decoder_attention_mask' : decoder_attention_mask,\n",
    "                 'labels' : labels, 'return_dict' : return_dict, 'output_hidden_states' : output_hidden_states, 'output_attentions' : output_attention}\n",
    "        if input_features != None : \n",
    "            inputs['input_features'] = input_features    \n",
    "\n",
    "        outputs = super().forward(**inputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9707b737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model__and_processor(model_path, quantization_level, lora_rank, lora_alpha) :\n",
    "    processor = WhisperProcessor.from_pretrained(model_path, language='en', task = \"transcribe\")\n",
    "    tokenizer = WhisperTokenizer.from_pretrained(model_path, language = 'en', task = \"transcribe\")\n",
    "    \n",
    "    if quantization_level == 8 :\n",
    "        bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "    if quantization_level == 4 :\n",
    "        bnb_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "    if quantization_level == None :\n",
    "        bnb_config = None\n",
    "        \n",
    "    custom_model = CustomWhisperModel.from_pretrained(model_path, quantization_config = bnb_config, device_map='auto')\n",
    "    q_model = prepare_model_for_kbit_training(custom_model)\n",
    "\n",
    "    peft_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, target_modules=[\"q_proj\", \"v_proj\"], \n",
    "                             r=lora_rank, lora_alpha=lora_alpha, lora_dropout=0.1)\n",
    "    model = get_peft_model(q_model, peft_config)\n",
    "    return model, tokenizer, processor"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bbe329811d1f68f1006062ddc421e37fadd9958e5320fe4c500df0d6792311cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
