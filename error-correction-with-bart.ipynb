{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":192920788,"sourceType":"kernelVersion"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport pickle\nfrom dataclasses import dataclass\nfrom torch.utils.data import Dataset\nfrom transformers import BartForConditionalGeneration, BartTokenizer, TrainingArguments, WhisperProcessor, Trainer\n\nbart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v3\", language='en')\nbart_tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\", language='en')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-24T04:25:02.269273Z","iopub.execute_input":"2024-08-24T04:25:02.269923Z","iopub.status.idle":"2024-08-24T04:25:41.523330Z","shell.execute_reply.started":"2024-08-24T04:25:02.269891Z","shell.execute_reply":"2024-08-24T04:25:41.522107Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-08-24 04:25:12.810350: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-24 04:25:12.810473: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-24 04:25:12.973837: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0989a21be8984789b76338443ded8ade"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60d84a70f10a4926be8c1bb49aeac863"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"781eed04fac94c1394f5155f7874ee6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73ec497f7ad74c2f8ccf759c35495bd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9997d5753244886827e095821263c3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60435b6d63524df2a64877a4c122a9eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8555bb4bd0fe4fb18a1876d8b76f1416"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5288b013b5d343fd9f60bc62a335cd78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db3ee182c0954a8393cade76460e1f4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"581c0c4efe2d405ab27e11ba6306f178"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"390c82c3a0f24d729ad52a09eaa41d91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec7688c7519e4afa8e5fb083f774b503"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a0b8bda76c44109990947dbfede45dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"067bd3c4d82b4e29873bfeae7dc919c4"}},"metadata":{}}]},{"cell_type":"code","source":"def total_params(model):\n    return sum(p.numel() for p in model.parameters())\n\nprint(f'Memory used by model: {round(bart_model.get_memory_footprint()/1024/1024/1024, 2)} GB')\nprint(f'total number of parameters is {total_params(bart_model)}')","metadata":{"execution":{"iopub.status.busy":"2024-08-24T04:25:41.526093Z","iopub.execute_input":"2024-08-24T04:25:41.528589Z","iopub.status.idle":"2024-08-24T04:25:41.540622Z","shell.execute_reply.started":"2024-08-24T04:25:41.528551Z","shell.execute_reply":"2024-08-24T04:25:41.539658Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Memory used by model: 1.51 GB\ntotal number of parameters is 406291456\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('/kaggle/input/whisper-output-notebook/sequences.pkl', mode='rb') as f:\n    sequences = pickle.load(f)\nwith open('/kaggle/input/whisper-output-notebook/labels.pkl', mode='rb') as f:\n    labels = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T04:25:41.545278Z","iopub.execute_input":"2024-08-24T04:25:41.545602Z","iopub.status.idle":"2024-08-24T04:25:43.621552Z","shell.execute_reply.started":"2024-08-24T04:25:41.545563Z","shell.execute_reply":"2024-08-24T04:25:43.620415Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"remove_values = {50364, 50257, 50258, 50259, 50260, 50261, 50262, 50263, 50264, 50265, 50266, 50267, 50268, 50269, 50270, 50271, 50272, 50273, 50274, 50275, 50276,\n                 50277, 50278, 50279, 50280, 50281, 50282, 50283, 50284, 50285, 50286, 50287, 50288, 50289, 50290, 50291, 50292, 50293, 50294, 50295, 50296, 50297, \n                 50299, 50300, 50301, 50302, 50303, 50304, 50305, 50306, 50307, 50308, 50309, 50310, 50311, 50312, 50313, 50314, 50315, 50316, 50317, 50318, 50319,\n                 50321, 50322, 50323, 50324, 50325, 50326, 50327, 50328, 50329, 50330, 50331, 50332, 50333, 50334, 50335, 50336, 50337, 50338, 50339, 50340, 50341,\n                 50343, 50344, 50345, 50346, 50347, 50348, 50349, 50350, 50351, 50352, 50353, 50354, 50355, 50356, 50357, 50358, 50359, 50360, 50361, 50362, 50363,\n                 50298, 50320, 50342}\n\nclass training_dataset(Dataset) :\n    def __init__(self, sequences, labels, remove_list) :\n        super().__init__()\n        self.sequences = sequences\n        self.labels = labels\n        self.remove_list = remove_list\n\n    def __len__(self) :\n        return self.labels.__len__()\n\n    def __getitem__(self, idx) :\n        output = {}\n        data = self.sequences[idx]\n        seq = [item for item in data if int(item) not in self.remove_list]\n        output['sequences'] = processor.tokenizer.decode(seq)\n        \n        labels = self.labels[idx][0]\n        labels = [item for item in labels if int(item) not in self.remove_list]\n        output['labels'] = processor.tokenizer.decode(labels)\n        \n        return output\n\ndataset = training_dataset(sequences, labels, remove_values)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T04:25:43.624047Z","iopub.execute_input":"2024-08-24T04:25:43.624374Z","iopub.status.idle":"2024-08-24T04:25:43.637227Z","shell.execute_reply.started":"2024-08-24T04:25:43.624346Z","shell.execute_reply":"2024-08-24T04:25:43.636215Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass data_collator :\n        \n    def __call__(self, features: dict):\n        \n        src_sentence = [feature['sequences'] for feature in features]\n        tgt_sentence = [feature['labels'] for feature in features]\n        scr = bart_tokenizer(src_sentence, padding='longest', truncation=True, max_length=100, return_token_type_ids=False, return_tensors='pt')\n        tgt = bart_tokenizer(tgt_sentence, padding='longest', truncation=True, max_length=100, return_token_type_ids=False, return_tensors='pt')\n        output = {}\n        output['input_ids'] = scr['input_ids']\n        output['labels'] = tgt['input_ids']\n        src_sentence = tgt_sentence = None\n        return output\n    \ncollator = data_collator()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T04:25:43.638608Z","iopub.execute_input":"2024-08-24T04:25:43.638882Z","iopub.status.idle":"2024-08-24T04:25:43.655408Z","shell.execute_reply.started":"2024-08-24T04:25:43.638857Z","shell.execute_reply":"2024-08-24T04:25:43.654331Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n                    output_dir=\"/kaggle/working/\",\n                    report_to = 'none',\n                    lr_scheduler_type='cosine',\n                    per_device_train_batch_size=16,\n                    learning_rate=3e-5,\n                    weight_decay = 2e-4,\n                    warmup_steps=40,\n                    num_train_epochs=1,\n                    max_steps=50,\n                    fp16=True,\n                    save_strategy = 'epoch',\n                    logging_steps=16,\n                    remove_unused_columns=False,\n                )\ntrainer = Trainer(model = bart_model, args=training_args, data_collator = collator, train_dataset = dataset)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T04:26:58.293799Z","iopub.execute_input":"2024-08-24T04:26:58.294213Z","iopub.status.idle":"2024-08-24T04:30:35.548017Z","shell.execute_reply.started":"2024-08-24T04:26:58.294164Z","shell.execute_reply":"2024-08-24T04:30:35.546615Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 03:30, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>16</td>\n      <td>8.673300</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>6.645300</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>4.666700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model \u001b[38;5;241m=\u001b[39m bart_model, args\u001b[38;5;241m=\u001b[39mtraining_args, data_collator \u001b[38;5;241m=\u001b[39m collator, train_dataset \u001b[38;5;241m=\u001b[39m dataset)\n\u001b[1;32m     17\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 18\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mstate_dict\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/model_weights.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'state_dict' is not defined"],"ename":"NameError","evalue":"name 'state_dict' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}